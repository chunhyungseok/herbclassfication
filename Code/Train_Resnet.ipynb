{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3385918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import torchvision.models as models\n",
    "\n",
    "warnings.simplefilter('ignore', Image.DecompressionBombWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94f698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "n_epochs = 100\n",
    "training_path = \"/DAS_Storage4/hyungseok/Training\"\n",
    "validation_path = \"/DAS_Storage4/hyungseok/Validation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c2f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82506a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose([transforms.Resize((128,128)),\n",
    "                           transforms.ToTensor(),                           \n",
    "                           transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                           ])\n",
    "valid_trans = transforms.Compose([transforms.Resize((128,128)),\n",
    "                           transforms.ToTensor(),                           \n",
    "                           transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                           ])\n",
    "trainset = torchvision.datasets.ImageFolder(root = training_path,\n",
    "                                           transform = train_trans)\n",
    "validset = torchvision.datasets.ImageFolder(root = validation_path,\n",
    "                                           transform = valid_trans)\n",
    "train_loader = DataLoader(trainset, batch_size = 256, shuffle = True)\n",
    "valid_loader = DataLoader(validset, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01569fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False)\n",
    "num_feature = model.fc.in_features\n",
    "model.fc = nn.Linear(num_feature, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5948ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "utils.init_weights(model, init_type='uniform')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas = (0.9, 0.98), eps = 1e-9, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c707b43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [02:34, 13.88s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    running_val_loss = 0.0\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    model.train()\n",
    "    \n",
    "    for idx, (x, y) in tqdm(enumerate(train_loader)):\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        train_total += y.size(0)\n",
    "        train_correct += (predicted == y).sum().item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for idx, (x, y) in tqdm(enumerate(valid_loader)):\n",
    "\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            valid_output = model(x)\n",
    "\n",
    "            valid_loss = criterion(valid_output, y)\n",
    "\n",
    "            running_val_loss += valid_loss.item()\n",
    "\n",
    "            _, predicted = torch.max(valid_output.data, 1)\n",
    "            valid_total += y.size(0)\n",
    "            valid_correct += (predicted == y).sum().item()\n",
    "            \n",
    "    torch.save({\n",
    "        'epoch' : epoch,\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "        'optimizer_state_dict' : optimizer.state_dict(),\n",
    "        'loss' : loss\n",
    "    }, 'model/{}-new_model.pt'.format(epoch+1))\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    print('Epoch {}/{}, Train_Acc: {:.3f}, Train_Loss : {:.6f}, valid_Acc : {:3f}, Valid_Loss : {:.6f}'.format(epoch+1,n_epochs, \n",
    "                                                                                                              train_correct/train_total,\n",
    "                                                                                                              running_loss / len(train_loader),\n",
    "                                                                                                             valid_correct/valid_total,\n",
    "                                                                                                              valid_loss / len(valid_loader)\n",
    "                                                                                                             ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670f8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98ccc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f65d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709edd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb85a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65441f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86029650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053efb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686920dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ced96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cef940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c3f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aecd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073695f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5230375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d5573f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e5afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8da76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
